Hyperparameters:
  num_epochs: 50
  batch_size: 64
  val_batch_size: 256
  patience: 2
  num_workers: 4

Optimizer:
  name: Adam
  lr: 0.001  # larger learning rate need for chinese

Architecture:
  model_type: rec
  algorithm: SVTR_LCNet
  Transform:
  Backbone:
    name: PPLCNetV3
    scale: 0.95
  Neck:
    name: SequenceEncoder
    encoder_type: svtr
    dims: 120
    depth: 2
    hidden_dims: 120
    kernel_size: [ 1, 3 ]
    use_guide: True
  Head:
    name: CTCHead

Loss:
  name: CTCLoss

PostProcess:
  name: CTCLabelDecode

Metric:
  name: RecMetric

Dataset:
  name: TextRecognitionDataset
  image_height: 48
  image_width: 320
  preprocesses:
    - CTCLabelEncode:
        max_text_length: 80