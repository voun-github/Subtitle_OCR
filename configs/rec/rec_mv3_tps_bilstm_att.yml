Hyperparameters:
  num_epochs: 10
  batch_size: 64
  val_batch_size: 256
  patience: 2
  num_workers: 4

Optimizer:
  name: Adam
  lr: 0.0005

Architecture:
  model_type: rec
  algorithm: RARE
  Transform:
    name: TPS
    num_fiducial: 20
    loc_lr: 0.1
    model_name: small
  Backbone:
    name: MobileNetV3
    scale: 0.5
    model_name: large
  Neck:
    name: SequenceEncoder
    encoder_type: rnn
    hidden_size: 96
  Head:
    name: AttentionHead
    hidden_size: 96

Loss:
  name: AttentionLoss

PostProcess:
  name: AttnLabelDecode

Metric:
  name: RecMetric

Dataset:
  name: TextRecognitionDataset
  image_height: 32
  image_width: 100
  preprocesses:
    - AttnLabelEncode:
        max_text_length: 40